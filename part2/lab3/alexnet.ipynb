{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/io/image.py:11: UserWarning: Failed to load image Python extension: dlopen(/Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libpng16.16.dylib\n",
      "  Referenced from: /Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/Users/malfet/miniforge3/envs/py_39_torch-1.10.2/lib/libpng16.16.dylib' (no such file), '/Users/malfet/miniforge3/envs/py_39_torch-1.10.2/lib/libpng16.16.dylib' (no such file), '/Users/malfet/miniforge3/envs/py_39_torch-1.10.2/lib/libpng16.16.dylib' (no such file), '/Users/malfet/miniforge3/envs/py_39_torch-1.10.2/lib/libpng16.16.dylib' (no such file), '/usr/local/lib/libpng16.16.dylib' (no such file), '/usr/lib/libpng16.16.dylib' (no such file)\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "# Импортируем основные модули pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Импортируем модули, связанные с компьютерным зрением\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as T  # пакет transforms будет доступен под именем T\n",
    "from torchvision.models import alexnet  # импортируем модель AlexNet\n",
    "\n",
    "# Импортируем вспомогательные модули\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# В данной лабораторной работе предлагается дообучить предобученные модели на уже известном нам наборе CIFAR10.\n",
    "# В этой части предлагается поработать с архитектурой AlexNet.\n",
    "# Необходимо:\n",
    "# 1. Подготовить изображения (см. ниже);\n",
    "# 2. \"Заморозить\" веса предобученной модели;\n",
    "# 3. Заменить последний слой для соответствия размерности выхода 10-яти классам;\n",
    "# 4. Дообучить модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Последовательность преобразований исходных изображений. Нужно заполнить.\n",
    "# Смысл этих преобразований в том, чтобы привести входные изображения из набора CIFAR10 к тому виду, который был у\n",
    "# изображений из набора, на котором была предобучена сеть. А именно:\n",
    "# 1. Картинки 3-ех канальные с размером 224 х 224 пикселей.\n",
    "# 2. Картики должны быть преобразованы в тензор и иметь цветовые компоненты на отрезке [0; 1].\n",
    "# 3. Среднее по цветовым каналам должно быть [0.485, 0.456, 0.406], а среднеквадратическое отклонение [0.229, 0.224, 0.225].\n",
    "# Посмотрите документацию по классам Compose, Resize, CenterCrop, ToTensor, Normalize из пакета torchvision.transforms.\n",
    "transforms = T.Compose([\n",
    "    # ВАШ КОД ЗДЕСЬ\n",
    "    T.Resize(256),\n",
    "    T.CenterCrop(224),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    # ===============\n",
    "])\n",
    "\n",
    "# Задаем количество эпох (проходов по всей обучающей выборке) и размер пакета, можно варьировать\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# Загружаем данные из набора CIFAR10\n",
    "train_data = datasets.CIFAR10(root='./data/train', train=True, download=True, transform=transforms)\n",
    "test_data = datasets.CIFAR10(root='./data/test', train=False, download=True, transform=transforms)\n",
    "\n",
    "# DataLoader позволяет разбить выборку на пакеты заданного размера.\n",
    "# Параметр shuffle отвечает за перемешивание данных в пакете\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если графический ускоритель поддерживает обучение на нем, будем использовать его,\n",
    "# иначе обучать на процессоре.\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model = alexnet(pretrained=True)  # загружаем модель с предобученными весами\n",
    "# Здесь необходимо выполнить 2-ой и 3-ий пункты.\n",
    "# ВАШ КОД ЗДЕСЬ\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=10)\n",
    "# ===============\n",
    "\n",
    "# Готовимся к обучению\n",
    "model = model.to(device)  # переносим модель на доступное устройство\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()))  # оптимизатор, нужно выбрать и настроить\n",
    "loss_function = nn.CrossEntropyLoss()  # функция потерь, нужно выбрать\n",
    "loss_history = list()  # список для хранения истории изменения функции стоимости"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [05:24,  1.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1 завершилась с функцией стоимости на последнем пакете = 0.5753809213638306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [02:18,  1.74s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (batch, labels) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(train_loader)):  \u001b[39m# разбиваем выборку на пакеты\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=3'>4</a>\u001b[0m     \u001b[39m# Нужно реализовать один шаг градиентного спуска\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=4'>5</a>\u001b[0m     \u001b[39m# loss = torch.tensor(0, dtype=torch.float32)  # значение функции стоимости на пакете, нужно рассчитать\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=5'>6</a>\u001b[0m     \u001b[39m# ВАШ КОД ЗДЕСЬ\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=6'>7</a>\u001b[0m     model\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=7'>8</a>\u001b[0m     outputs \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=8'>9</a>\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(outputs, labels)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wibbn/projects/rtu/ml/part2/lab3/alexnet.ipynb#ch0000002?line=9'>10</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/models/alexnet.py:46\u001b[0m, in \u001b[0;36mAlexNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/models/alexnet.py?line=44'>45</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[0;32m---> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/models/alexnet.py?line=45'>46</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures(x)\n\u001b[1;32m     <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/models/alexnet.py?line=46'>47</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n\u001b[1;32m     <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torchvision/models/alexnet.py?line=47'>48</a>\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///Users/wibbn/.pyenv/versions/3.9.9/envs/ml/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Начинаем обучение\n",
    "for epoch in range(EPOCHS):\n",
    "    for i, (batch, labels) in tqdm(enumerate(train_loader)):  # разбиваем выборку на пакеты\n",
    "        # Нужно реализовать один шаг градиентного спуска\n",
    "        # loss = torch.tensor(0, dtype=torch.float32)  # значение функции стоимости на пакете, нужно рассчитать\n",
    "        # ВАШ КОД ЗДЕСЬ\n",
    "        model.zero_grad()\n",
    "        outputs = model(batch)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # ===============\n",
    "        loss_history.append(loss.log().item())  # добавляется логарифм стоимости для большей наглядности\n",
    "    print(f'Эпоха {epoch + 1} завершилась с функцией стоимости на последнем пакете = {loss.item()}')\n",
    "\n",
    "\n",
    "# Выводим график функции стоимости\n",
    "plt.title('Зависимость функции стоимости от номера шага градиентного спуска')\n",
    "plt.xlabel('Номер шага')\n",
    "plt.ylabel('Функция стоимости')\n",
    "plt.plot(loss_history)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Отключаем расчет вычислительного графа для экономии времени и памяти: нам не нужно считать градиенты при тестировании модели\n",
    "with torch.no_grad():\n",
    "    # Оцениваем качество модели\n",
    "    train_data_loader = DataLoader(train_data, batch_size=1024)\n",
    "    train_features, train_targets = next(iter(train_data_loader))\n",
    "\n",
    "    train_features = train_features.to(device)\n",
    "    train_model_predictions = torch.argmax(model(train_features), dim=1)\n",
    "    print('Точность (accuracy) на обучающей выборке:', accuracy_score(train_targets, train_model_predictions))\n",
    "\n",
    "    test_data_loader = DataLoader(test_data, batch_size=1024)\n",
    "    test_features, test_targets = next(iter(test_data_loader))\n",
    "\n",
    "    test_features = test_features.to(device)\n",
    "    test_model_predictions = torch.argmax(model(test_features), dim=1)\n",
    "    print('Точность (accuracy) на тестовой выборке:', accuracy_score(test_targets, test_model_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7d35ccc9069beebc945d05423ac0c6deb5a2cd97d7ddcaf21de10627e6326eb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
